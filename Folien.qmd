---
title: "Laborbericht"
date: today
date-format: long
autor: "Bernd Baalmann und Moritz Vossel"
format:
    revealjs:
        theme: default
        logo: /Bilder/DHBW_CAS_LOGO_Sonderform.jpg
        css: /css/logo.css
        footer: "Bernd Baalmann und Moritz Vossel | DHBW CAS | Laborbericht Data Science"
        number-sections: true
        scrollable: true
        fontsize: 26pt
        code-tools:
          source: https://github.com/quarto-dev/quarto-web/blob/main/index.md
        highlight-style: github
jupyter: python3
---
```{python}
# | echo: false
## Quarto dependency
from IPython.display import display, Markdown

## Standard libraries
import os, math, time
import numpy as np

## Imports for plotting
import matplotlib.pyplot as plt
%matplotlib inline 
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('svg', 'pdf') # For export
from matplotlib.colors import to_rgba
import seaborn as sns
sns.set()
```


# Einleitung

<br>

:::: {.columns}

::: {.column width="50%"}
:::

::: {.column width="50%"}

![Abbildung: PyTorch Logo. Quelle: PyTorch 2023](/Bilder/PyTorch_Logo.png){width=4in}
:::


::::

## Was ist PyTorch?
<br>
- Open-Source Machine Learning Library zur Erstellung von ANN<br>
- Entwickelt von Facebooks AI-Team <br>
- Ermöglicht Erstellung, Fitting und Evaluation von komplexen NN<br>
- Praktische Tools wie dynamische Computation Graphs, optimiert für effiziente GPU-Berechnung (Parallel Processing)<br>
- Alternative Frameworks wären z.B. TensorFlow (Google) oder JAX<br>
- Große Entwickler-Community<br>
- Man kann Gradient/Ableitung automatisch erhalten<br>



## Setup

::: {.panel-tabset}

### Tab 1
Welche Libraries werden für die Übung benötigt?
```{python}
# | echo: true

## Progress bar
from tqdm.notebook import tqdm

# Torch import
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
```

### Tab 2
Setzen eines Seeds für die PyTorch Zufallszahlengenerierung zur Wiederholbarkeit der Forschungsergebnisse:
```{python}
# | echo: true
torch.manual_seed(42) # Setting the seed
```
:::

# Was sind Tensoren?


## Erstellen von Tensoren
::: {.panel-tabset}
### Tab 1
Erstellen eines Tensors mit der Größe 2 x 3 x 4
```{python}
# | echo: true
x = torch.Tensor(2, 3, 4)
print(x)
```

### Tab 2
Erstellung von einem Tensor über eine nested List:
```{python}
# | echo: true
x = torch.Tensor([[1, 2], [3, 4]])
print(x)
```

### Tab 3
Erstellung eines Tensors mit zufälligen Werten zwischen 0 und 1:
```{python}
# | echo: true
x = torch.rand(2, 3, 4)
print(x)
```
:::

## Bearbeiten von Tensoren
::: {.panel-tabset}
### Tab 1
Welche Größe hat der erstellte Tensor?
```{python}
# | echo: true
shape = x.shape
print("Shape:", x.shape)

size = x.size()
print("Size:", size)

dim1, dim2, dim3 = x.size()
print("Size:", dim1, dim2, dim3)
```

### Tab 2
Numpy Arrays lassen sich ohne weiteres in Tensoren umwandeln.
```{python}
# | echo: true
np_arr = np.array([[1, 2], [3, 4]])
tensor = torch.from_numpy(np_arr)

print("Numpy array:", np_arr)
print("PyTorch tensor:", tensor)
```

### Tab 3
Tensoren lassen sich ohne weiteres in Numpy Arrays umwandeln.
```{python}
# | echo: true
tensor = torch.arange(4)
np_arr = tensor.numpy()

print("PyTorch tensor:", tensor)
print("Numpy array:", np_arr)
```
:::

## Rechnen mit Tensoren
::: {.panel-tabset}
### Tab 1
Die meisten Operationen, die in numpy möglich sind, lassen sich auch in PyTorch ausführen. <br>
<br>
Matrix Addition über Operator.
```{python}
# | echo: true
# | output-location: column

x1 = torch.rand(2, 3)
x2 = torch.rand(2, 3)
y = x1 + x2

print("X1", x1)
print("X2", x2)
print("Y", y)
```

### Tab 2
Matrix Addition über eine Funktion.
```{python}
# | echo: true
# | output-location: column
x1 = torch.rand(2, 3)
x2 = torch.rand(2, 3)
print("X1 (before)", x1)
print("X2 (before)", x2)
 
x2.add_(x1)
print("X1 (after)", x1)
print("X2 (after)", x2)
```

### Tab 3
Generierung eines Tensors in der Range von 0 bis kleiner 6.
```{python}
# | echo: true
# | output-location: column
x = torch.arange(6)
print("X", x)
```


```{python}
# | echo: false
x = x.view(2, 3)
# print("X", x)
```

```{python}
# | echo: false
x = x.permute(1, 0) # Swapping dimension 0 and 1
# print("X", x)
```

```{python}
# | echo: false
x = torch.arange(6)
x = x.view(2, 3)
# print("X", x)
```

### Tab 4
Kombination von mehreren Operationen
```{python}
# | echo: true
# | output-location: column
W = torch.arange(9).view(3, 3)
print("W", W)
```
<br>
Matrixmultiplikation über Funktion Matmul
```{python}
# | echo: true
# | output-location: column
h = torch.matmul(x, W) # Verify the result by calculating it by hand too!
print("h", h)
```

```{python}
# | echo: false
x = torch.arange(12).view(3, 4)
# print("X", x)
```
:::

## Dynamic Computation Graph and Backpropagation
::: {.panel-tabset}
### Tab 1
Gradient capability = Tensor speichert und berechnet Gradienten, die für Backpropagation benötigt werden.<br><br>
Backpropagation = Parameter werden angepasst, um Loss-Funktion zu minimieren.
By default ist requires_grad in PyTorch false => wenn auf True gesetzt, werden Gradienten der Loss-Funktion automatisch berechnet<br>

### Tab 2
In den Standardeinstellungen erfordern Tensoren keine Gradienten.

```{python}
# | echo: true
# | output-location: column
x = torch.ones((3,))
print(x.requires_grad)
```
<br>
Das kann geändert werden indem man die Funktion requires_grad_ aufruft.
```{python}
# | echo: true
# | output-location: column
x.requires_grad_(True)
print(x.requires_grad)
```

### Tab 3
Erstellen eines Tensors mit drei Elementen, Datentyp float und Gradientenfähigkeit (gradient capability). <br>


```{python}
# | echo: true
# | output-location: column
x = torch.arange(3,
dtype=torch.float32,
requires_grad=True) # Only float tensors can have gradients
print("X", x)
```
### Tab 4
$$y = \frac{1}{|x|}\sum_i \left[(x_i + 2)^2 + 3\right]$$
<br>
```{python}
# | echo: true
a = x + 2
b = a ** 2
c = b + 3
y = c.mean()
print("Y", y)
```
### Tab 5
Die backward()-Funktion wird benutzt um die Gradienten des Tensors y zu berechnen.
```{python}
# | echo: true
y.backward()
```
### Tab 6
Unser Gradient sieht wie folgt aus.
```{python}
# | echo: true
print(x.grad)
```

:::


## Ausführung auf CPU oder GPU
::: {.panel-tabset}
### Tab 1
Um festzustellen, ob ein GPU nutzbar ist, kann man folgenden Code ausführen.
```{python}
# | echo: true
gpu_avail = torch.cuda.is_available()
print(f"GPU availability: {gpu_avail}")
```
CUDA (Compute Unified  Device Architecture) ist Schnittstelle von NVIDIA mit der Programmteile durch GPU abgearbeitet werden können, was Parallel Computing ermöglicht. <br>
Es ist leider auf unserer Hardware keine GPU vorhanden.

### Tab 2
Aus diesem Grund verwenden wir in diesem Beispiel den CPU.
```{python}
# | echo: true
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print("Device", device)
```

### Tab 3
Hierzu gibt man bei der Operation das zu nutzende Device an.
```{python}
# | echo: true
x = torch.zeros(2, 3)
x = x.to(device)
print("X", x)
```
:::

##  GPU vs. CPU
::: {.panel-tabset}
### Tab 1
Ein kurzer Vergleich der Stärken von CPU und GPUs. <br>

![Tabelle: CPU vs. GPU. Quelle: Caulfield 2009](/Bilder/comparison_CPU_GPU.png)

### Tab 2
Um festzustellen was das quantitativ für gängige Kalkulationen bedeutet. Findet sich hier ein Vergleich zwischen der Ausführung auf einem GPU und einem CPU.
```{python}
# | echo: true
x = torch.randn(5000, 5000)

## CPU version
start_time = time.time()
_ = torch.matmul(x, x)
end_time = time.time()
print(f"CPU time: {(end_time - start_time):6.5f}s")

try:
    ## GPU version
    x = x.to(device)
    _ = torch.matmul(x, x)  # First operation to 'burn in' GPU
    # CUDA is asynchronous, so we need to use different timing functions
    start = torch.cuda.Event(enable_timing=True)
    end = torch.cuda.Event(enable_timing=True)
    start.record()
    _ = torch.matmul(x, x)
    end.record()
    torch.cuda.synchronize()  # Waits for everything to finish running on the GPU
    print(f"GPU time: {0.001 * start.elapsed_time(end):6.5f}s")  # Milliseconds to seconds
except:
    print("Error: GPU nicht nutzbar aufgrund Hardwarebeschränkung")
```


### Tab 3
Weil das ganze nicht auf unserer Hardware ausführbar war, haben wir die Ausführungszeiten beim Author des Tutorials recherchiert.<br>
CPU time: 0.20694s <br>
GPU time: 0.00985s <br>

### Tab 4
Für die GPU Operationen muss ein weiterer Seed gesetzt werden und definieren, dass alle Operationen deterministisch ausgeführt werden. 
```{python}
# | echo: true

if torch.cuda.is_available(): 
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```
:::

## Erstellen Modellen in Pytorch
::: {.panel-tabset}
### Tab 1
Unser Anwendungsbeispiel <br>

![Abbildung: Small Neural Network. Quelle: Lippe 2022](/Bilder/small_neural_network.png)


### Tab 2
XOR Wahrheitstafel <br>

| X_1   | X_2  | Output  |
|-------|------|---------|
|   1   |  1   |    0    |
|  1    |  0   |     1   |
|    0  |    1 |     1   |
|    0  |    0 |     0   |


### Tab 3
So sieht die Blaupause für die Erstellung von Modellen in PyTorch aus.
```{python}
# | echo: true
class MyModule(nn.Module):
    
    def __init__(self):
        super().__init__()
        # Some init for my module
        
    def forward(self, x):
        # Function for performing the calculation of the module.
        pass
```

### Tab 4
Eine Beispielimpelmentation könnte also wie folgt aussehen.
```{python}
# | echo: true
class SimpleClassifier(nn.Module):

    def __init__(self, num_inputs, num_hidden, num_outputs):
        super().__init__()
        # Initialize the modules we need to build the network
        self.linear1 = nn.Linear(num_inputs, num_hidden)
        self.act_fn = nn.Tanh()
        self.linear2 = nn.Linear(num_hidden, num_outputs)

    def forward(self, x):
        # Perform the calculation of the model to determine the prediction
        x = self.linear1(x)
        x = self.act_fn(x)
        x = self.linear2(x)
        return x
```

```{python}
# | echo: false
model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)
# Printing a module shows all its submodules
# print(model)
```

```{python}
# | echo: false
# for name, param in model.named_parameters():
#     print(f"Parameter {name}, shape {param.shape}")
```
:::


## Generierung von Datensätzen in PyTorch
::: {.panel-tabset}
### Tab 1
Eine Beispielimplementation in PyTorch könnte zum Beispiel so aussehen.
```{python}
# | echo: true
class XORDataset(data.Dataset):

    def __init__(self, size, std=0.1):
        """
        Inputs:
            size - Number of data points we want to generate
            std - Standard deviation of the noise (see generate_continuous_xor function)
        """
        super().__init__()
        self.size = size
        self.std = std
        self.generate_continuous_xor()

    def generate_continuous_xor(self):
        # Each data point in the XOR dataset has two variables, x and y, that can be either 0 or 1
        # The label is their XOR combination, i.e. 1 if only x or only y is 1 while the other is 0.
        # If x=y, the label is 0.
        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)
        label = (data.sum(dim=1) == 1).to(torch.long)
        # To make it slightly more challenging, we add a bit of gaussian noise to the data points.
        data += self.std * torch.randn(data.shape)

        self.data = data
        self.label = label

    def __len__(self):
        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]
        return self.size

    def __getitem__(self, idx):
        # Return the idx-th data point of the dataset
        # If we have multiple things to return (data point and label), we can return them as tuple
        data_point = self.data[idx]
        data_label = self.label[idx]
        return data_point, data_label
```

### Tab 2
Mit dieser Klasse kann man dann geeignete Daten erzeugen.
```{python}
# | echo: true
# | output-location: column
dataset = XORDataset(size=200)
print("Size of dataset:", len(dataset))
print("Data point 0:", dataset[0])
```



```{python}
# | echo: false
def visualize_samples(data, label):
    if isinstance(data, torch.Tensor):
        data = data.cpu().numpy()
    if isinstance(label, torch.Tensor):
        label = label.cpu().numpy()
    data_0 = data[label == 0]
    data_1 = data[label == 1]
    
    plt.figure(figsize=(4,4))
    plt.scatter(data_0[:,0], data_0[:,1], edgecolor="#333", label="Class 0")
    plt.scatter(data_1[:,0], data_1[:,1], edgecolor="#333", label="Class 1")
    plt.title("Dataset samples")
    plt.ylabel(r"$x_2$")
    plt.xlabel(r"$x_1$")
    plt.legend()
```

### Tab 3

```{python}
# | echo: true
# | output-location: column
visualize_samples(dataset.data,
dataset.label)
plt.show()
```
:::

## Laden von Datensätzen in PyTorch
Bei großen Datensätzen kann es vorteilhaft sein den Datensatz in Batches zu laden. Dies ermöglicht PyTorch durch Multiprocessing.

```{python}
# | echo: true
data_loader = data.DataLoader(dataset,
                              batch_size=8,
                              shuffle=True)
```


# Optimierung

## Erstellung eines Loss Models.
Loss-Funktion berechnet Differenz zwischen Vorhersagen des Netzwerks und „echten“ Labels. In PyTorch sehr einfach mit vordefinierten Loss-Funktionen möglich. <br>
Hier binäres Klassifikationsproblem, daher Benutzung von Binary Cross Entropy (BCE)<br>

```{python}
# | echo: true
loss_module = nn.BCEWithLogitsLoss()
```

## Erstellen eines Gradienten Verfahrens
Parameter sollen so angepasst werden, dass der Loss minimiert wird. <br>
In PyTorch sind im torch.optim-Package viele Optimizer vordefiniert. 
Einfachster Optimizer ist Stochastic Gradient Descent (SGD).
Learning Rate (lr) wird auf 0.1 gesetzt. 

```{python}
# | echo: true
# Input to the optimizer are the parameters of the model: model.parameters()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
```


## Modellerstellung
::: {.panel-tabset}
### Tab 1
Training eines Modells mit den zuvor erstellten Parametern
```{python}
# | echo: true
train_dataset = XORDataset(size=2500)
train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=True)
```

### Tab 2
Das Modell an das durchführende Device schicken.
```{python}
# | echo: true
model.to(device)
```

### Tab 3
Definition des Trainingsfunktion eines Modells.
```{python}
# | echo: true
def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):
    # Set model to train mode
    model.train() 
    
    # Training loop
    for epoch in tqdm(range(num_epochs)):
        for data_inputs, data_labels in data_loader:
            
            ## Step 1: Move input data to device (only strictly necessary if we use GPU)
            data_inputs = data_inputs.to(device)
            data_labels = data_labels.to(device)
            
            ## Step 2: Run the model on the input data
            preds = model(data_inputs)
            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]
            
            ## Step 3: Calculate the loss
            loss = loss_module(preds, data_labels.float())
            
            ## Step 4: Perform backpropagation
            # Before calculating the gradients, we need to ensure that they are all zero. 
            # The gradients would not be overwritten, but actually added to the existing ones.
            optimizer.zero_grad() 
            # Perform backpropagation
            loss.backward()
            
            ## Step 5: Update the parameters
            optimizer.step()
```


### Tab 4
Training des Modells
```{python}
# | echo: true
train_model(model,
            optimizer,
            train_data_loader,
            loss_module)
```
Auf den Trainingsdaten erreichen wir eine Accurracy von 100%.

### tab 5
So sieht unser Modell nach dem Training aus.
```{python}
# | echo: true
state_dict = model.state_dict()
print(state_dict)
```
<br>
Danach können wir das Modell speichern.
```{python}
# | echo: true
torch.save(state_dict, "our_model.tar")
```

### tab 6
Und später wieder laden
```{python}
# | echo: true
# Load state dict from the disk (make sure it is the same name as above)
state_dict = torch.load("our_model.tar")

# Create a new model and load the state
new_model = SimpleClassifier(num_inputs=2, num_hidden=4, num_outputs=1)
new_model.load_state_dict(state_dict)

# Verify that the parameters are the same
print("Original model\n", model.state_dict())
print("\nLoaded model\n", new_model.state_dict())
```
:::

## Testen des Modells
::: {.panel-tabset}
### Tab 1
Generierung von Testdaten
```{python}
# | echo: true
test_dataset = XORDataset(size=500)
test_data_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False, drop_last=False) 
```

### Tab 2
Definition einer Evaluierungsfunktion.
```{python}
# | echo: true
def eval_model(model, data_loader):
    model.eval() # Set model to eval mode
    true_preds, num_preds = 0., 0.
    
    with torch.no_grad(): # Deactivate gradients for the following code
        for data_inputs, data_labels in data_loader:
            
            # Determine prediction of model on dev set
            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)
            preds = model(data_inputs)
            preds = preds.squeeze(dim=1)
            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1
            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1
            
            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)
            true_preds += (pred_labels == data_labels).sum()
            num_preds += data_labels.shape[0]
            
    acc = true_preds / num_preds
    print(f"Accuracy of the model: {100.0*acc:4.2f}%")
```

### Tab 3
Ausführen der Evaluierungsfunktion mit den Testdaten.
```{python}
# | echo: true
eval_model(model, test_data_loader)
```

### Tab 4
Visualisierung der Klassifikation
```{python}
# | echo: true
# | output-location: column
@torch.no_grad() # Decorator, same effect as "with torch.no_grad(): ..." over the whole function.
def visualize_classification(model, data, label):
    if isinstance(data, torch.Tensor):
        data = data.cpu().numpy()
    if isinstance(label, torch.Tensor):
        label = label.cpu().numpy()
    data_0 = data[label == 0]
    data_1 = data[label == 1]
    
    fig = plt.figure(figsize=(4,4), dpi=500)
    plt.scatter(data_0[:,0], data_0[:,1], edgecolor="#333", label="Class 0")
    plt.scatter(data_1[:,0], data_1[:,1], edgecolor="#333", label="Class 1")
    plt.title("Dataset samples")
    plt.ylabel(r"$x_2$")
    plt.xlabel(r"$x_1$")
    plt.legend()
    
    # Let's make use of a lot of operations we have learned above
    model.to(device)
    c0 = torch.Tensor(to_rgba("C0")).to(device)
    c1 = torch.Tensor(to_rgba("C1")).to(device)
    x1 = torch.arange(-0.5, 1.5, step=0.01, device=device)
    x2 = torch.arange(-0.5, 1.5, step=0.01, device=device)
    xx1, xx2 = torch.meshgrid(x1, x2, indexing='ij')  # Meshgrid function as in numpy
    model_inputs = torch.stack([xx1, xx2], dim=-1)
    preds = model(model_inputs)
    preds = torch.sigmoid(preds)
    output_image = (1 - preds) * c0[None,None] + preds * c1[None,None]  # Specifying "None" in a dimension creates a new one
    output_image = output_image.cpu().numpy()  # Convert to numpy array. This only works for tensors on CPU, hence first push to CPU
    plt.imshow(output_image, origin='lower', extent=(-0.5, 1.5, -0.5, 1.5))
    plt.grid(False)
    return fig

_ = visualize_classification(model, dataset.data, dataset.label)
plt.show()
```

:::

# Weitere Features

## Tensorboard Logging
::: {.panel-tabset}
### Tab 1
```{python}
# | echo: true
# Load tensorboard extension for Jupyter Notebook, only need to start TB in the notebook
%load_ext tensorboard

```

### Tab 2
```{python}
# | echo: true
# | output-location: fragment
def train_model_with_logger(model, optimizer, data_loader, loss_module, val_dataset, num_epochs=100, logging_dir='runs/our_experiment'):
    # Create TensorBoard logger
    writer = SummaryWriter(logging_dir)
    model_plotted = False
    
    # Set model to train mode
    model.train() 
    
    # Training loop
    for epoch in tqdm(range(num_epochs)):
        epoch_loss = 0.0
        for data_inputs, data_labels in data_loader:
            
            ## Step 1: Move input data to device (only strictly necessary if we use GPU)
            data_inputs = data_inputs.to(device)
            data_labels = data_labels.to(device)
            
            # For the very first batch, we visualize the computation graph in TensorBoard
            if not model_plotted:
                writer.add_graph(model, data_inputs)
                model_plotted = True
            
            ## Step 2: Run the model on the input data
            preds = model(data_inputs)
            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]
            
            ## Step 3: Calculate the loss
            loss = loss_module(preds, data_labels.float())
            
            ## Step 4: Perform backpropagation
            # Before calculating the gradients, we need to ensure that they are all zero. 
            # The gradients would not be overwritten, but actually added to the existing ones.
            optimizer.zero_grad() 
            # Perform backpropagation
            loss.backward()
            
            ## Step 5: Update the parameters
            optimizer.step()
            
            ## Step 6: Take the running average of the loss
            epoch_loss += loss.item()
            
        # Add average loss to TensorBoard
        epoch_loss /= len(data_loader)
        writer.add_scalar('training_loss',
                          epoch_loss,
                          global_step = epoch + 1)
        
        # Visualize prediction and add figure to TensorBoard
        # Since matplotlib figures can be slow in rendering, we only do it every 10th epoch
        if (epoch + 1) % 10 == 0:
            fig = visualize_classification(model, val_dataset.data, val_dataset.label)
            writer.add_figure('predictions',
                              fig,
                              global_step = epoch + 1)
    
    writer.close()
```

### Tab 3
```{python}
# | echo: true
model = SimpleClassifier(num_inputs=2,
                        num_hidden=4,
                        num_outputs=1).to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
train_model_with_logger(model,
                        optimizer,
                        train_data_loader,
                        loss_module,
                        val_dataset=dataset)
```

### Tab 4
```{python}
# | echo: true
%tensorboard --logdir runs/our_experiment
```

:::

::: {.notes}
Speaker notes go here.
:::

# Zusammenfassung


## References

Unsere Implementation baut auf dem Turtorial von Phillip Lippe auf. Siehe:
<br>
**Filled notebook:** 
[![View filled on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb)
[![Open filled In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb)   
**Recordings:** 
[![YouTube - Part 1](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%201&color=red)](https://youtu.be/wnKZZgFQY-E)
[![YouTube - Part 2](https://img.shields.io/static/v1.svg?logo=youtube&label=YouTube&message=Part%202&color=red)](https://youtu.be/schbjeU5X2g)   

## Backup {visibility="uncounted"}